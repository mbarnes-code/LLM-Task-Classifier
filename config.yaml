# production_config.yaml

task_generation:
  min_tasks_per_subject: 50000         # Minimum tasks to accumulate before writing a Parquet file
  max_tasks_per_subject: 100000         # Maximum tasks per Parquet file (after which a new file is created)
  batch_size: 200                       # Number of tasks to generate per batch
  max_iterations: 2                     # Number of complete iterations over the text chunks

bias_detection:
  threshold: 0.1                        # Allowed overrepresentation ratio per domain (10% over the expected share)
  max_rebalancing_attempts: 5           # Maximum rebalancing attempts before aborting generation
  min_tasks_before_rebalancing: 5000    # Minimum tasks required before rebalancing checks

dataset_monitoring:
  size_limit_gb: 50                     # (Optional) Notify if dataset file exceeds this size

device_config:
  device: "auto"                        # Options: "auto", "cpu", or "cuda"
  enable_fp16: true                     # Enable FP16 if GPU supports it

logging:
  level: "INFO"                         
  log_file: "/var/log/task_generation.log"  
  enable_console: false                 
  rotate: true                          
  max_file_size: "100MB"                
  backup_count: 5                       

parallel_processing:
  enabled: true
  num_workers: 8                        # Number of parallel workers for file processing

subject_extraction:
  keywords:
    General:
      - "general"
    Finance:
      - "bank"
      - "finance"
      - "investment"
      - "market"
    HR:
      - "human resource"
      - "employee"
      - "recruitment"
    IT:
      - "software"
      - "it"
      - "technology"
      - "computer"
    Operations:
      - "operation"
      - "supply chain"
      - "logistics"
    Sales:
      - "sales"
      - "revenue"
      - "customer"
      - "market"

model_config:
  model_name: "distilbert-base-uncased"  
  summarizer_model: "facebook/bart-large-cnn"  # Model for generating summaries from text chunks
  inference_batch_size: 16

storage:
  input_folder: "/data/documents"        # Path where input documents are stored
  output_folder: "/data/parquet_output"    # Path to save generated Parquet files

airflow:
  dag_name: "training_data_ingestion"
  schedule_interval: "0 2 * * *"           # Example: Daily at 2 AM

alerts:
  enable_email_alerts: true
  email_recipients:
    - "ops@example.com"
    - "admin@example.com"
  alert_threshold: 0.05
